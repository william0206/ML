{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import CategoricalNB\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score\nimport math\nimport scipy.stats as stats\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Data Input\n\ndf = pd.read_csv('../input/hw1-data/iris.csv', header = None)\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\ndf.rename(columns={0: \"sepal length\", 1: \"sepal width\", 2: \"petal length\", 3: \"petal width\", 4: \"class\"}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data visualization\ndata = df.describe()\nindex = np.arange(2)\nbar_width = 0.2\nalpha = 0.6\nplt.style.use('ggplot')\n\nfor fe in df.columns[:4]:\n    plt.bar(index,\n            data[fe][1:3], \n            bar_width,\n            alpha = alpha,\n            label=fe)\n    index = index + 0.2\n\nplt.ylabel(\"cm\")\n# plt.xlabel(\"\")\nplt.title(\"Data distribution\")\nplt.xticks(index - 0.8 + 0.5 / 2 ,(\"average\",\"standard deviation\"))\nplt.legend() \nplt.grid(True)\nplt.savefig('iris_data_distribution.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.describe()\nindex = np.array([0.1, 0.5])\nbar_width = 0.1\nalpha = 0.6\nplt.style.use('ggplot')\n\nfor fe in df.columns[:4]:\n    for c in np.unique(df['class']):\n        plt.bar(index,\n                df.loc[df['class'] == c].describe()[fe][1:3], \n                bar_width,\n                alpha = alpha,\n                label=c)\n        index = index + 0.1\n    plt.ylabel(\"cm\")\n    # plt.xlabel(\"\")\n    plt.title(\"feature distribution: \" + fe)\n    plt.xticks(index - 0.6 + 0.8 / 2 ,(\"average\",\"standard deviation\"))\n    plt.legend() \n    plt.grid(True)\n    plt.savefig('iris_by_class_' + fe + '_distribution.png')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kwargs = dict(histtype='stepfilled', alpha=0.7, bins=10, ec=\"k\")\nfor fe in df.columns[:4]:\n    plt.style.use('ggplot')\n    plt.hist(df[fe], **kwargs, label=fe)        \n    \nplt.title(\"Data distribution\")\nplt.ylabel(\"value frequency\")\nplt.xlabel(\"cm\")\nplt.grid(True)\nplt.legend()\nplt.savefig('iris_freture_frequency.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kwargs = dict(histtype='stepfilled', alpha=0.6, bins=10, ec=\"k\")\nfor fe in df.columns[:4]:\n    for c in np.unique(df['class']):\n        plt.style.use('ggplot')\n        plt.hist(df.loc[df['class'] == c][fe], **kwargs, label=c)        \n    \n    plt.title(\"feature distribution: \" + fe)\n    plt.ylabel(\"Value Frequency\")\n    plt.xlabel(\"cm\")\n    plt.grid(True)\n    plt.legend()\n    plt.savefig('iris_by_class_' + fe + '.png')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Preprocessing\n\n#drop missing value feature\n\n#shuffle the data\ndf = shuffle(df, random_state =0)\ndf.reset_index(inplace=True, drop=True)\n#prepare x,y for model\ny = df['class'].copy()\nX = df.drop(['class'], axis=1).copy()\nnp.unique(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Construction with Holdout validation\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=0)\n\nclf = GaussianNB()\n# clf = CategoricalNB(alpha= 0)\nclf.fit(X_train, y_train)\ny_true, y_pred = y_valid, clf.predict(X_valid)\n\n#Show result\nprint(pd.DataFrame(confusion_matrix(y_true, y_pred, labels = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']), index= ['actually setosa', 'actually versicolor', 'actually virginica'], columns= ['predict setosa', 'predict versicolor', 'predict virginica']))\nprint('\\naccuracy  {:.7}'.format(accuracy_score(y_true, y_pred)))\nprint('\\n          setosa   versicolor   virginica\\nrecall    {:.7}      {:.7}    {:.7}'.format(recall_score(y_true, y_pred, average = None)[0], recall_score(y_true, y_pred, average = None)[1], recall_score(y_true, y_pred, average = None)[2]))\nprint('precision {:.7}      {:.7}          {:.7}'.format(precision_score(y_true, y_pred, average = None)[0], precision_score(y_true, y_pred, average = None)[1], recall_score(y_true, y_pred, average = None)[2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Question\nx = pd.concat([X_train, y_train],  axis=1)\nx = (x.loc[x['class'] == 'Iris-versicolor']['petal length']).to_numpy()\nmean = np.mean(x)\nstd = np.std(x)\n\nkwargs = dict(histtype='stepfilled', alpha=0.7, density=True, bins=10, ec=\"k\")\nplt.hist(x, **kwargs)\nxmin, xmax = plt.xlim()\nx_axis = np.linspace(xmin, xmax, 100)\ny_axis = stats.norm.pdf(x_axis, mean, std)\n\nplt.style.use('ggplot')\nplt.title(\"pdf\")\nplt.text(3.05, 1.01, \"μ = {:.7f}\\nσ = {:.7f}\".format(mean, std),fontsize=14)\nplt.ylabel(\"Density\")\nplt.xlabel(\"petal length(cm)\")\nplt.grid(True)\nplt.plot(x_axis, y_axis)\nplt.savefig('iris_pdf.png')\nplt.show()\n\n# print('mean:{:.7f}\\nstd:{:.7f}'.format(mean, std))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Construction with K-fold cross-validation\n\ncfm = []\nacc = []\nsen = []\npre = []\n\nkf = KFold(n_splits=3)\nkf.get_n_splits(X)\n\nfor train_index, vali_index in kf.split(X):\n#     print(\"TRAIN:\", train_index, \"TEST:\", vali_index)\n    X_train, X_valid = X.values[train_index], X.values[vali_index]\n    y_train, y_valid = y.values[train_index], y.values[vali_index]\n    \n    clf = GaussianNB()\n    # clf = CategoricalNB(alpha= 0)\n    clf.fit(X_train, y_train)\n    y_true, y_pred = y_valid, clf.predict(X_valid)\n\n    cfm.append(confusion_matrix(y_true, y_pred, labels = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']))\n    acc.append(accuracy_score(y_true, y_pred))\n    sen.append(recall_score(y_true, y_pred, average = None))\n    pre.append(precision_score(y_true, y_pred, average = None))\n\n#Show result\nprint(pd.DataFrame((cfm[0] + cfm[1] + cfm[2]) / 3, index= ['actually setosa', 'actually versicolor', 'actually virginica'], columns= ['predict setosa', 'predict versicolor', 'predict virginica']).round(0).astype(int))\nprint('\\naccuracy  {:.7}'.format(sum(acc) / len(acc)))\nprint('\\n          setosa   versicolor   virginica\\nrecall    {:.7}      {:.7}    {:.7}'.format(((sen[0] + sen[1] + sen[2]) / 3)[0], ((sen[0] + sen[1] + sen[2]) / 3)[1], ((sen[0] + sen[1] + sen[2]) / 3)[2]))\nprint('precision {:.7}      {:.7}    {:.7}'.format(((pre[0] + pre[1] + pre[2]) / 3)[0], ((pre[0] + pre[1] + pre[2]) / 3)[1], ((sen[0] + sen[1] + sen[2]) / 3)[2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Question\n# fig_df = pd.DataFrame([0, 0, 0, 0, 0, 0, 0, 0, 0], index= ['b', 'c', 'e', 'g', 'n', 'o', 'p', 'w', 'y'], columns= ['prob']) \n# num_e = df.loc[df[0] == 'e'].shape[0]\n# num_e_and_fe14 = df.loc[df[0] == 'e'].groupby(14).size()\n# cat = list(num_e_and_fe14.index)\n# for i in range(0, len(cat)):\n#     fig_df.loc[cat[i], 'prob'] += (num_e_and_fe14[i] / num_e)\n# fig_df","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}