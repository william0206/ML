{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import CategoricalNB\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Data Input\n\ndf = pd.read_csv('../input/hw1-data/agaricus-lepiota.csv', header = None)\npd.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Visualization\nplt.style.use('ggplot')\nkwargs = dict(alpha=0.7, color = 'g', ec=\"k\")\n\nfor fe in df.columns[1:]:\n    plt.bar(np.unique(df[fe]), df.groupby(fe).size().values, **kwargs)\n    plt.title(\"Feature\" + str(fe))\n    plt.xlabel(\"feature value\")\n    plt.ylabel(\"value frequency\")\n    plt.grid(True)\n    plt.savefig(str(fe) + '.png')\n    plt.show()\n\nkwargs['color'] = 'b'    \nfor fe in df.loc[df[0] == 'e'].columns[1:]:\n    plt.bar(np.unique(df.loc[df[0] == 'e'][fe]), df.loc[df[0] == 'e'].groupby(fe).size().values, **kwargs)\n    plt.title(\"Feature\" + str(fe))\n    plt.xlabel(\"feature value\")\n    plt.ylabel(\"value frequency\")\n    plt.grid(True)\n    plt.savefig('e_' + str(fe) + '.png')\n    plt.show()\nkwargs['color'] = 'orange' \nfor fe in df.loc[df[0] == 'p'].columns[1:]:\n    plt.bar(np.unique(df.loc[df[0] == 'p'][fe]), df.loc[df[0] == 'p'].groupby(fe).size().values, **kwargs)\n    plt.title(\"Feature\" + str(fe))\n    plt.xlabel(\"feature value\")\n    plt.ylabel(\"value frequency\")\n    plt.grid(True)\n    plt.savefig('p_' + str(fe) + '.png')\n    plt.show()\n\n# \n# plt.ylabel(\"value frequency\")\n# plt.xlabel(\"cm\")\n# plt.grid(True)\n# plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Preprocessing\n\n#drop missing value feature\ndf.drop([11], axis=1, inplace=True)\n#shuffle the data\ndf = shuffle(df, random_state = 0)\ndf.reset_index(inplace=True, drop=True)\n#prepare x,y for model\ny = df[0].copy()\nX = df.drop([0], axis=1).copy()\n#do Ohe-Hot encoding\nX = pd.get_dummies(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Construction with Holdout validation\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=0)\n\nclf = CategoricalNB()\n# clf = CategoricalNB(alpha= 0)\nclf.fit(X_train, y_train)\ny_true, y_pred = y_valid, clf.predict(X_valid)\n\n#Show result\nprint(pd.DataFrame(confusion_matrix(y_true, y_pred, labels = ['e', 'p']), index= ['actually e', 'actually p'], columns= ['predict e', 'predict p']))\nprint('\\naccuracy  {:.7}'.format(accuracy_score(y_true, y_pred)))\nprint('\\n          e          p\\nrecall    {:.7}  {:.7}'.format(recall_score(y_true, y_pred, average = None)[0], recall_score(y_true, y_pred, average = None)[1]))\nprint('precision {:.7}  {:.7}'.format(precision_score(y_true, y_pred, average = None)[0], precision_score(y_true, y_pred, average = None)[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Construction with K-fold cross-validation\n\ncfm = []\nacc = []\nsen = []\npre = []\n\nkf = KFold(n_splits=3)\nkf.get_n_splits(X)\n\nfor train_index, vali_index in kf.split(X):\n#     print(\"TRAIN:\", train_index, \"TEST:\", vali_index)\n    X_train, X_valid = X.values[train_index], X.values[vali_index]\n    y_train, y_valid = y.values[train_index], y.values[vali_index]\n    \n    clf = CategoricalNB()\n#     clf = CategoricalNB(alpha= 0)\n    clf.fit(X_train, y_train)\n    y_true, y_pred = y_valid, clf.predict(X_valid)\n\n    cfm.append(confusion_matrix(y_true, y_pred, labels = ['e', 'p']))\n    acc.append(accuracy_score(y_true, y_pred))\n    sen.append(recall_score(y_true, y_pred, average = None))\n    pre.append(precision_score(y_true, y_pred, average = None))\n\n#Show result\nprint(pd.DataFrame((cfm[0] + cfm[1] + cfm[2]) / 3, index= ['actually e', 'actually p'], columns= ['predict e', 'predict p']).round(0).astype(int))\nprint('\\naccuracy  {:.7}'.format(sum(acc) / len(acc)))\nprint('\\n          e          p\\nrecall    {:.7}  {:.7}'.format(((sen[0] + sen[1] + sen[2]) / 3)[0], ((sen[0] + sen[1] + sen[2]) / 3)[1]))\nprint('precision {:.7}  {:.7}'.format(((pre[0] + pre[1] + pre[2]) / 3)[0], ((pre[0] + pre[1] + pre[2]) / 3)[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Question\nfig_df = pd.DataFrame([0, 0, 0, 0, 0, 0, 0, 0, 0], index= ['b', 'c', 'e', 'g', 'n', 'o', 'p', 'w', 'y'], columns= ['prob'])\nfig_df_lps = pd.DataFrame([0, 0, 0, 0, 0, 0, 0, 0, 0], index= ['b', 'c', 'e', 'g', 'n', 'o', 'p', 'w', 'y'], columns= ['prob'])\nnum_e = df.loc[df[0] == 'e'].shape[0]\nnum_e_and_fe14 = df.loc[df[0] == 'e'].groupby(14).size()\ncat = list(num_e_and_fe14.index)\nfor i in range(0, len(cat)):\n    fig_df.loc[cat[i], 'prob'] += (num_e_and_fe14[i] / num_e)\n    fig_df_lps.loc[cat[i], 'prob'] += ((num_e_and_fe14[i] + 1) / (num_e + 1*9))\nfig_df_lps.loc[fig_df_lps['prob'] == 0] = (1/(num_e + 1*9))\n\nprint(fig_df)\nprint(fig_df_lps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('ggplot')\nb = plt.bar(fig_df.index, fig_df['prob'], color = 'blue', alpha=0.7)\nplt.title(\"without Laplace smoothing        \")\nplt.xlabel(\"feature value\")\nplt.ylabel(\"probability\")\nplt.grid(True)\nfor item in b:\n        height = item.get_height()\n        plt.text(\n            item.get_x() + item.get_width()/2., \n            height*1.05, \n            '%.4f' % float(height),\n            ha = \"center\",\n            va = \"bottom\",\n            rotation = 60\n        )\nplt.savefig('without Laplace smoothing.png')\nplt.show()\n\nb = plt.bar(fig_df_lps.index, fig_df_lps['prob'], color = 'red', alpha=0.7)\nplt.title(\"with Laplace smoothing        \")\nplt.xlabel(\"feature value\")\nplt.ylabel(\"probability\")\nplt.grid(True)\nfor item in b:\n        height = item.get_height()\n        plt.text(\n            item.get_x() + item.get_width()/2., \n            height*1.05, \n            '%.4f' % float(height),\n            ha = \"center\",\n            va = \"bottom\",\n            rotation = 60\n        )\nplt.savefig('with Laplace smoothing.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}